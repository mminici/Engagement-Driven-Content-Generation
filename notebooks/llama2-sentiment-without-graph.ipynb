{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from gae import *\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"1,2,3\"\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    Adafactor,\n",
    "    AutoTokenizer,\n",
    "    LlamaTokenizer,\n",
    "    HfArgumentParser,\n",
    "    pipeline\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer, set_seed\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "from MyPPOTrainer import *\n",
    "from MyLoraConfig import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"</s>\"\n",
    "DEFAULT_UNK_TOKEN = \"</s>\"\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "@dataclass\n",
    "class ScriptArguments:\n",
    "    \"\"\"\n",
    "    The name of the Casual LM model we wish to fine with PPO\n",
    "    \"\"\"\n",
    "\n",
    "    # NOTE: gpt2 models use Conv1D instead of Linear layers which are not yet supported in 8 bit mode\n",
    "    # models like gpt-neo* models are more suitable.\n",
    "    model_name: Optional[str] = field(default=\"NousResearch/Llama-2-7b-chat-hf\", metadata={\"help\": \"the model name\"})\n",
    "    tokenizer_name: Optional[str] = field(default=\"\", metadata={\"help\": \"the tokenizer name\"})\n",
    "    reward_model_name: Optional[str] = field(default=\"lvwerra/distilbert-imdb\", metadata={\"help\": \"the reward model name\"})\n",
    "    dataset_name: Optional[str] = field(default=\"\", metadata={\"help\": \"the dataset name\"})\n",
    "    log_with: Optional[str] = field(default=\"wandb\", metadata={\"help\": \"use 'wandb' to log with wandb\"})\n",
    "    learning_rate: Optional[float] = field(default=1.41e-5, metadata={\"help\": \"the learning rate\"})\n",
    "    max_length: Optional[int] = field(default=512, metadata={\"help\": \"maximum length for input\"})\n",
    "    output_max_length: Optional[int] = field(default=128, metadata={\"help\": \"maximum length for generation\"})\n",
    "    mini_batch_size: Optional[int] = field(default=1, metadata={\"help\": \"the PPO minibatch size\"})\n",
    "    batch_size: Optional[int] = field(default=8, metadata={\"help\": \"the batch size\"})\n",
    "    ppo_epochs: Optional[int] = field(default=1, metadata={\"help\": \"the number of ppo epochs\"})\n",
    "    gradient_accumulation_steps: Optional[int] = field(\n",
    "        default=4, metadata={\"help\": \"the number of gradient accumulation steps\"}\n",
    "    )\n",
    "    adafactor: Optional[bool] = field(default=False, metadata={\"help\": \"whether to use the adafactor optimizer\"})\n",
    "    early_stopping: Optional[bool] = field(default=True, metadata={\"help\": \"whether to early stop\"})\n",
    "    target_kl: Optional[float] = field(default=0.1, metadata={\"help\": \"kl target for early stopping\"})\n",
    "    reward_baseline: Optional[float] = field(\n",
    "        default=0.0,\n",
    "        metadata={\"help\": \"a baseline value that is subtracted from the reward\"},\n",
    "    )\n",
    "    batched_gen: Optional[bool] = field(default=False, metadata={\"help\": \"whether to use the batched text gen\"})\n",
    "    save_freq: Optional[int] = field(default=None, metadata={\"help\": \"n steps to save the model\"})\n",
    "    output_dir: Optional[str] = field(default=\"/mnt/nas/coppolillo/LLMs/ppo_checkpoints/\",\n",
    "                                      metadata={\"help\": \"n steps to save the model\"})\n",
    "    seed: Optional[int] = field(default=0, metadata={\"help\": \"the seed\"})\n",
    "\n",
    "\n",
    "#parser = HfArgumentParser(ScriptArguments)\n",
    "#script_args: ScriptArguments = parser.parse_args_into_dataclasses()[0]\n",
    "parser = HfArgumentParser((ScriptArguments,))\n",
    "script_args = parser.parse_args_into_dataclasses(return_remaining_strings=True)[0]\n",
    "set_seed(script_args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Propagation Model\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "\n",
    "from data_component import DataComponent\n",
    "from information_diffusion_component import BoundedConfidenceDiffusionComponent\n",
    "\n",
    "# synthetic data generator params\n",
    "num_nodes = 100\n",
    "modularity = 0.5\n",
    "homophily = 0.5\n",
    "\n",
    "# bounded confidence model params\n",
    "epsilon = 0.2\n",
    "mu = 0.5\n",
    "\n",
    "llm_node_id = 0\n",
    "\n",
    "data = DataComponent(num_nodes, modularity, homophily)\n",
    "data.pre_compute_neighboring()  # save neighbors for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinions stats \n",
      "mean: 0.43409650762652613\n",
      "std: 0.2531177104552777\n",
      "min: 0.004124513320711887\n",
      "max: 0.9853385079483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'occurrences')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "information_diffusion_model = BoundedConfidenceDiffusionComponent(data_component=data, epsilon=epsilon, mu=mu)\n",
    "\n",
    "opinions = information_diffusion_model.get_opinions()\n",
    "print(f'Opinions stats \\nmean: {opinions.mean()}\\nstd: {opinions.std()}\\nmin: {opinions.min()}\\nmax: {opinions.max()}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "_ = plt.hist(opinions, bins=25, range=[0,1])\n",
    "plt.xlabel('opinion value')\n",
    "plt.ylabel('occurrences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = {}\n",
    "for n in data.G.nodes():\n",
    "    attrs.update({n: {\"y\": n, \"x\": [opinions[n]]}})\n",
    "nx.set_node_attributes(data.G, attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52558ae764c5402cb58251e02bd0d643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d27161700540fea199f88cb40f9ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Below is an example function to build the dataset. In our case, we use the IMDB dataset\n",
    "# from the `datasets` library. One should customize this function to train the model on\n",
    "# its own dataset.\n",
    "def build_dataset(\n",
    "        tokenizer, dataset_name, input_min_text_length=2, input_max_text_length=8\n",
    "):\n",
    "    \"\"\"\n",
    "    Build dataset for training. This builds the dataset from `load_dataset`, one should\n",
    "    customize this function to train the model on its own dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (`str`):\n",
    "            The name of the dataset to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dataloader (`torch.utils.data.DataLoader`):\n",
    "            The dataloader for the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    #train_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    \n",
    "    prompt = \"Generate a post about cats.\" \n",
    "    \n",
    "    size = 10000\n",
    "    df = pd.DataFrame(np.repeat(prompt, size), columns=[\"0\"])\n",
    "    ds = Dataset.from_dict(df)\n",
    "    \n",
    "    train_dataset = ds.rename_columns({\"0\": \"question\"})\n",
    "    \n",
    "    original_columns = train_dataset.column_names\n",
    "    num_proc = 24\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        new_examples = {\n",
    "            \"query\": [],\n",
    "            \"input_ids\": [],\n",
    "        }\n",
    "        for question in examples[\"question\"]:\n",
    "            query = \"Question: \" + question + \"\\n\\nAnswer: \\n\"\n",
    "            tokenized_question = tokenizer(query, truncation=True, max_length=script_args.max_length)\n",
    "            new_examples[\"query\"].append(query)\n",
    "            new_examples[\"input_ids\"].append(tokenized_question[\"input_ids\"])\n",
    "\n",
    "        return new_examples\n",
    "\n",
    "    ds = train_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        num_proc=num_proc,\n",
    "        remove_columns=original_columns,\n",
    "    )\n",
    "    ds = ds.filter(lambda x: len(x[\"input_ids\"]) <= script_args.max_length, batched=False)\n",
    "\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "\n",
    "reward_model_name = script_args.reward_model_name\n",
    "config = PPOConfig(\n",
    "    model_name=script_args.model_name,\n",
    "    learning_rate=script_args.learning_rate,\n",
    "    log_with=script_args.log_with,\n",
    "    batch_size=script_args.batch_size,\n",
    "    mini_batch_size=script_args.mini_batch_size,\n",
    "    gradient_accumulation_steps=script_args.gradient_accumulation_steps,\n",
    "    optimize_cuda_cache=True,\n",
    "    early_stopping=script_args.early_stopping,\n",
    "    target_kl=script_args.target_kl,\n",
    "    ppo_epochs=script_args.ppo_epochs,\n",
    "    seed=script_args.seed\n",
    ")\n",
    "\n",
    "# We then define the arguments to pass to the sentiment analysis pipeline.\n",
    "# We set `return_all_scores` to True to get the sentiment score for each token.\n",
    "rw_kwargs = {\n",
    "    \"return_all_scores\": True,\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\": script_args.batch_size,\n",
    "    \"truncation\": True\n",
    "}\n",
    "\n",
    "if \"decapoda\" in script_args.model_name.lower():\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(script_args.model_name)\n",
    "    # required for llama\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\n",
    "            \"eos_token\": DEFAULT_EOS_TOKEN,\n",
    "            \"bos_token\": DEFAULT_BOS_TOKEN,\n",
    "            \"unk_token\": DEFAULT_UNK_TOKEN,\n",
    "            \"pad_token\": DEFAULT_PAD_TOKEN,\n",
    "        }\n",
    "    )\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(script_args.model_name)\n",
    "    if getattr(tokenizer, \"pad_token\", None) is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# We retrieve the dataloader by calling the `build_dataset` function.\n",
    "dataset = build_dataset(tokenizer, script_args.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query', 'input_ids'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NousResearch/Llama-2-7b-chat-hf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363e9d867ffd4cfdb72383bdd48bc0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coppolillo/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/coppolillo/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/coppolillo/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/coppolillo/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33merica-coppolillo\u001b[0m (\u001b[33mfinetuning-llms\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/coppolillo/Desktop/LLMs/wandb/run-20240302_093447-n8m8heuy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/finetuning-llms/trl/runs/n8m8heuy' target=\"_blank\">confused-firefly-121</a></strong> to <a href='https://wandb.ai/finetuning-llms/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/finetuning-llms/trl' target=\"_blank\">https://wandb.ai/finetuning-llms/trl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/finetuning-llms/trl/runs/n8m8heuy' target=\"_blank\">https://wandb.ai/finetuning-llms/trl/runs/n8m8heuy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's build the model, the reference model, and the tokenizer.\n",
    "# current_device = Accelerator().local_process_index\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "    config.model_name,\n",
    "    load_in_8bit=False,\n",
    "    device_map=\"auto\",\n",
    "    peft_config=lora_config\n",
    ")\n",
    "\n",
    "optimizer = None\n",
    "if script_args.adafactor:\n",
    "    optimizer = Adafactor(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        scale_parameter=False,\n",
    "        relative_step=False,\n",
    "        warmup_init=False,\n",
    "        lr=config.learning_rate,\n",
    "    )\n",
    "\n",
    "# We then build the PPOTrainer, passing the model, the reference model, the tokenizer\n",
    "ppo_trainer = PPOTrainer(\n",
    "    config,\n",
    "    model,\n",
    "    ref_model=None,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=dataset,\n",
    "    data_collator=collator,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PPOConfig(exp_name='ipykernel_launcher', seed=0, log_with='wandb', task_name=None, model_name='NousResearch/Llama-2-7b-chat-hf', query_dataset='imdb', reward_model='sentiment-analysis:lvwerra/distilbert-imdb', remove_unused_columns=True, tracker_kwargs={}, accelerator_kwargs={}, project_kwargs={}, tracker_project_name='trl', push_to_hub_if_best_kwargs={}, steps=20000, learning_rate=1.41e-05, adap_kl_ctrl=True, init_kl_coef=0.2, kl_penalty='kl', target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=0.1, batch_size=8, forward_batch_size=None, mini_batch_size=1, gradient_accumulation_steps=4, world_size=1, ppo_epochs=1, max_grad_norm=None, optimize_cuda_cache=True, optimize_device_cache=False, early_stopping=True, target_kl=0.1, compare_steps=1, ratio_threshold=10.0, use_score_scaling=False, use_score_norm=False, score_clip=None, whiten_rewards=False, is_encoder_decoder=False, is_peft_model=True, backward_batch_size=4, global_backward_batch_size=4, global_batch_size=8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ppo_trainer.accelerator.device\n",
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"  # to avoid a ` pipeline` bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True\n",
    "\n",
    "output_min_length = 32\n",
    "output_max_length = script_args.output_max_length\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = pipeline(\"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                          | 0/1250 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/coppolillo/venv/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "  0%|▉                                                                                                                                                                                              | 6/1250 [06:51<22:35:24, 65.37s/it]"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "\n",
    "    # We then build the sentiment analysis pipeline, passing the model name and the\n",
    "    # sentiment analysis pipeline arguments. Let's also make sure to set the device\n",
    "    # to the same device as the PPOTrainer.\n",
    "\n",
    "    # reward_model = pipeline(\"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\")\n",
    "\n",
    "    # We then define the arguments to pass to the `generate` function. These arguments\n",
    "    # are passed to the `generate` function of the PPOTrainer, which is a wrapper around\n",
    "    # the `generate` function of the trained model.\n",
    "    generation_kwargs = {\n",
    "        # \"min_length\": -1,\n",
    "        \"top_k\": 0.0,\n",
    "        \"top_p\": 1.0,\n",
    "        \"do_sample\": True,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "        \"eos_token_id\": 100_000\n",
    "    }\n",
    "   \n",
    "\n",
    "    for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader), total=len(ppo_trainer.dataloader)):\n",
    "        question_tensors = batch[\"input_ids\"]\n",
    "\n",
    "        response_tensors = ppo_trainer.generate(\n",
    "            question_tensors,\n",
    "            return_prompt=False,\n",
    "            length_sampler=output_length_sampler,\n",
    "            **generation_kwargs,\n",
    "        )\n",
    "        batch[\"response\"] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
    "\n",
    "        # Compute sentiment score\n",
    "        texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "        sentiment_outputs = sentiment_model(texts, **rw_kwargs)\n",
    "        # rewards = [torch.tensor(output[0][\"score\"] - script_args.reward_baseline) for output in reward_outputs]\n",
    "\n",
    "        messages_values = [output[1][\"score\"] for output in sentiment_outputs]\n",
    "\n",
    "        rewards = []\n",
    "        for message_value in messages_values:\n",
    "            opinion_shift_tot, num_activated_users, _ = information_diffusion_model.propagate_message(message=message_value,\n",
    "                                                                                          node_id=llm_node_id)\n",
    "            rewards.append(torch.tensor(num_activated_users, dtype=torch.float))\n",
    "\n",
    "\n",
    "        # Run PPO step\n",
    "        stats = ppo_trainer.step(question_tensors, response_tensors, rewards)\n",
    "        ppo_trainer.log_stats(stats, batch, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = script_args.output_dir + \"llama2-sentiment-propagation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(saving_path):\n",
    "    os.makedirs(saving_path)\n",
    "\n",
    "model.save_pretrained(saving_path)\n",
    "tokenizer.save_pretrained(saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_args.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ref_model = \"cuda:0\"\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(script_args.model_name, device_map=device_ref_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD = False  # \n",
    "\n",
    "if LOAD:\n",
    "    device_model = \"auto\"\n",
    "            \n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        saving_path,\n",
    "        device_map=device_model\n",
    "    )\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(saving_path)\n",
    "    \n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    ppo_trainer = PPOTrainer(config, model, None, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ref_model.parameters())==list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### get a batch from the dataset\n",
    "bs = 16\n",
    "game_data = dict()\n",
    "dataset.set_format(\"pandas\")\n",
    "df_batch = dataset[:].sample(bs)\n",
    "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "query_tensors = df_batch[\"input_ids\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tensors_ref = [] \n",
    "\n",
    "gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \n",
    "              \"pad_token_id\": tokenizer.eos_token_id}\n",
    "\n",
    "for i in range(bs):\n",
    "    gen_len = output_length_sampler()\n",
    "    output = ref_model.generate(\n",
    "        torch.tensor(query_tensors[i], device=device_ref_model).unsqueeze(dim=0), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors_ref.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tensors = []\n",
    "\n",
    "for i in range(bs):\n",
    "    output = ppo_trainer.generate(\n",
    "    torch.tensor(query_tensors[i]), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### decode responses\n",
    "game_data[\"response (before)\"] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
    "game_data[\"response (after)\"] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
    "\n",
    "#### sentiment analysis of query/response pairs before/after\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n",
    "# game_data[\"rewards (before)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)] # [output for output in calc_rewards(texts)] # \n",
    "game_data_sentiments = [output[1][\"score\"] for output in sentiment_model(texts, **rw_kwargs)] # [output for output in calc_rewards(texts)] # \n",
    "game_data[\"rewards (before)\"] = [information_diffusion_model.propagate_message(message=x,\n",
    "                                  node_id=llm_node_id)[1] for x in game_data_sentiments] # [output for output in calc_rewards(texts)] # \n",
    "\n",
    "\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n",
    "#game_data[\"rewards (after)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)] # [output for output in calc_rewards(texts)] # \n",
    "game_data_sentiments = [output[1][\"score\"] for output in sentiment_model(texts, **rw_kwargs)] # [output for output in calc_rewards(texts)] # \n",
    "game_data[\"rewards (after)\"] = [information_diffusion_model.propagate_message(message=x,\n",
    "                                  node_id=llm_node_id)[1] for x in game_data_sentiments]\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(game_data)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the reward mean/median of the generated sequences we observe a significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].mean())\n",
    "print()\n",
    "print(\"median:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data[\"response (after)\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c8ff454cd947027f86954d72bf940c689a97dcc494eb53cfe4813862c6065fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
